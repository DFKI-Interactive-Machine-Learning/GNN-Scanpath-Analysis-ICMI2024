{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import os\n",
    "from dataclasses import dataclass, asdict\n",
    "import pandas as pd\n",
    "import json\n",
    "from collections import Counter\n",
    "from data_loading.data_loader import SciBot_DataLoader  # Provided From https://github.com/DFKI-Interactive-Machine-Learning/gazeRE-dataset \n",
    "from gaze_event_detection.idt import fixation_detection \n",
    "from gaze_event_detection.saccade_detection import compute_saccade_aoi_features\n",
    "from gaze_event_detection.convex_hull_area_features import compute_area_aoi_features\n",
    "\n",
    "from statistics import mean, stdev"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "@dataclass\n",
    "class NodeGraphDataClass:\n",
    "    __slots__ = [\"user_id\", \"stimulus\", \"label\", \"edge_index\", \"node_features\", \"system_label\"]\n",
    "    user_id: str\n",
    "    stimulus: str\n",
    "    edge_index: list\n",
    "    node_features: list\n",
    "    label: list\n",
    "    system_label: list"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6c998018f4d626ce",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "@dataclass\n",
    "class NodeAOIDataClass:\n",
    "    __slots__ = [\"user_id\", \"stimulus\", \"aoi_scanpath\", \"node_features\", \"label\", \"system_label\"]\n",
    "    user_id: str\n",
    "    stimulus: str\n",
    "    label: list\n",
    "    aoi_scanpath: list\n",
    "    node_features: dict\n",
    "    system_label: list"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "87fb9940a25c4381",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def assign_aoi(scanpath_graph_representation_type: str, current_stimulus_id: str, x_point, y_point) -> int:\n",
    "    \"\"\"\n",
    "    For each fixation we assign which AOI it falls in.\n",
    "        The title takes number 0.\n",
    "        The paragraphs take numbers from 1 until #Paragraphs.\n",
    "        If the fixation is on an empty space or on the rating button it takes number 100.\n",
    "    We discard the rating button since the original publication didn't take it into perspective.\n",
    "    Based on the stimuli, we check that the fixation is with 700 and 1800 to make sure it fell on text and not on empty space. \n",
    "    This function does not deal with Cluster-based scanpath graph representations.\n",
    "    \"\"\"\n",
    "    aoi_id = 100\n",
    "    directory_path = f\"../Data/Stimuli_Coordinates_Data/GoogleNQ_{scanpath_graph_representation_type}_AOI.json\" \n",
    "    with open(directory_path, 'r') as fp:\n",
    "        dict_coordinates = json.load(fp)\n",
    "    if dict_coordinates is not None:\n",
    "        if 700 <= x_point <= 1800:\n",
    "            for AOI in dict_coordinates[current_stimulus_id]:\n",
    "                if dict_coordinates[current_stimulus_id][AOI][\"y_bottom\"] <= y_point <= dict_coordinates[current_stimulus_id][AOI][\"y_top\"]:\n",
    "                    aoi_id = AOI\n",
    "    else:\n",
    "        print(\"Wrong Coordinates\")\n",
    "    return int(aoi_id)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "29645a6112380a12",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def get_stimulus_node_size(scanpath_graph_representation_type: str, current_stimulus_id: str) -> int:\n",
    "    \"\"\"\n",
    "    :param scanpath_graph_representation_type: Scanpath graph representation.\n",
    "    :param current_stimulus_id: Get the current stimulus ID to check the number of AOIs.\n",
    "    :return: Number of AOIs in the stimulus CSV + 1 because of the current setup where the image coordinates are not in the CSV file\n",
    "    \"\"\"\n",
    "    directory_path = f\"../Data/Stimuli_Coordinates_Data/GoogleNQ_{scanpath_graph_representation_type}_AOI.json\" \n",
    "    with open(directory_path, 'r') as fp:\n",
    "        dict_coordinates = json.load(fp)\n",
    "    aoi_length = len(dict_coordinates[current_stimulus_id])\n",
    "    return aoi_length"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "35c6a0245fdf2419",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def get_maximum_node_size(scanpath_graph_representation_type: str):\n",
    "    maximum_aoi_length = 0\n",
    "    directory_path = f\"../Data/Stimuli_Coordinates_Data/GoogleNQ_{scanpath_graph_representation_type}_AOI.json\"\n",
    "    with open(directory_path, 'r') as fp:\n",
    "        dict_coordinates = json.load(fp)\n",
    "    for stimuli_id in dict_coordinates:\n",
    "        stimuli_length = len(dict_coordinates[stimuli_id])\n",
    "        if stimuli_length > maximum_aoi_length:\n",
    "            maximum_aoi_length = stimuli_length\n",
    "    return maximum_aoi_length"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7f285a1353524747",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def compute_path(aoi_list: list) -> list:\n",
    "    \"\"\"\n",
    "    Here we extract the transitions between paragraphs.\n",
    "    \"\"\"\n",
    "    aoi_path = []\n",
    "    for i in range(len(aoi_list)):\n",
    "            if i == len(aoi_list) - 1:\n",
    "                aoi_path.append(aoi_list[i])\n",
    "            elif aoi_list[i] != aoi_list[i + 1]:  # If two consecutive fixations have different AOIs then it's a transition\n",
    "                aoi_path.append(aoi_list[i])\n",
    "    aoi_path = [i for i in aoi_path if i != 100]  # We don't take the empty space transitions into account\n",
    "    return aoi_path"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b3a35fbe568e896f",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def extract_graph_data(dataclass_aoi_data: NodeAOIDataClass) -> NodeGraphDataClass:\n",
    "    \"\"\"\n",
    "    The GNN expects (maximum node ID = number of nodes-1) to be the maximum number that appears in the aoi_pairs.\n",
    "        We pre-add zeros in the aoi_features equal to the maximum number of AOIs we have in the stimuli.\n",
    "        Some AOI IDs have 0 fixations, which is why we pre-initiate the nodes with Zeros to make sure that all nodes, even empty ones, are accounted for. \n",
    "    node_size:param can either be the stimulus size using get_stimulus_node_size(), or the maximum node size for zero padding using get_maximum_node_size()\n",
    "    \"\"\"\n",
    "    scanpath = dataclass_aoi_data.aoi_scanpath\n",
    "    aoi_pairs = []\n",
    "    for i in range(0, len(scanpath)):\n",
    "            if 0 <= i < len(scanpath) - 1:\n",
    "                aoi_pairs.append([scanpath[i], scanpath[i + 1]])\n",
    "    graph_features = [value for key, value in dataclass_aoi_data.node_features.items()]\n",
    "    graph_data = NodeGraphDataClass(user_id=dataclass_aoi_data.user_id, stimulus=dataclass_aoi_data.stimulus, label=dataclass_aoi_data.label, \n",
    "                                edge_index=aoi_pairs, node_features=graph_features, system_label=dataclass_aoi_data.system_label)\n",
    "    return graph_data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "70c4085e49b7fc59",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\"\"\"\n",
    "The eye tracking data and the data loader are both from https://github.com/DFKI-Interactive-Machine-Learning/gazeRE-dataset \n",
    "The data folder was renamed Eye_Tracking_Data to avoid confusion since we have other data as well. \n",
    "\"\"\"\n",
    "# load data\n",
    "users_ids = [\"A01\", \"A03\", \"A04\", \"A06\", \"A07\", \"A08\", \"A09\", \"A10\", \"A11\", \"A12\", \"A13\",\n",
    "             \"B01\", \"B02\", \"B03\", \"B04\", \"B05\", \"B06\", \"B07\", \"B08\", \"B09\", \"B10\", \"B11\", \"B12\", \"B13\"]\n",
    "dataloader = SciBot_DataLoader(data_dir=\"../Data/Eye_Tracking_Data\", include_users=users_ids,\n",
    "                               gaze_data=True, reading_task=True, rating_task=False, training_data=False, gREL=False)\n",
    "items = dataloader.google_nq_reading.items()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b01fdd4863a5f60c",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\"\"\"\n",
    "Define graph data parameters\n",
    "    scanpath_graph_representation: \"Paragraph\"\n",
    "    only_two_node_features: True, False\n",
    "\"\"\"\n",
    "scanpath_graph_representation = \"Paragraph\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dd8896c82b8bf011",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for only_two_node_features in [True, False]:\n",
    "    output_df = pd.DataFrame(columns=[\"user_id\", \"stimulus\", \"label\", \"edge_index\", \"node_features\", \"system_label\"])\n",
    "    num_node_features = 0\n",
    "    for user, user_data in items:\n",
    "        for filename in os.listdir(f\"../Data/Eye_Tracking_Data/stimuli/Google_NQ/\"):\n",
    "            document_id = filename[0:-4]\n",
    "            stimulus = filename[0:-4]\n",
    "            stimulus_number_of_aoi = get_stimulus_node_size(scanpath_graph_representation_type=scanpath_graph_representation, current_stimulus_id=stimulus)\n",
    "    \n",
    "            dict_aoi_fixation_durations = {100: []}  # 100 is for empty spaces\n",
    "            dict_features_per_aoi = {100: {\"fixation_counts\": 0, \"fixation_duration_sum\": 0, \"fixation_duration_mean\": 0, \"fixation_duration_std\": 0, \"scan_distance_h\": 0, \"scan_distance_v\": 0, \"scan_distance_euclid\": 0, \"scan_hv_ratio\": 0, \"avg_sacc_length\": 0, \"scan_speed_h\": 0, \"scan_speed_v\": 0, \"scan_speed\": 0}} \n",
    "            dict_fixation_features_per_aoi = {100: {\"fixation_duration_sum\": 0, \"fixation_duration_mean\": 0, \"fixation_duration_std\": 0}}  # 100 is the AOI ID for empty spaces, which will be removed\n",
    "            list_stimulus_aois = [i for i in range(stimulus_number_of_aoi)]\n",
    "            list_stimulus_aois.append(100)\n",
    "            for stimulus_aoi in range(stimulus_number_of_aoi):\n",
    "                dict_aoi_fixation_durations[stimulus_aoi] = []\n",
    "                dict_fixation_features_per_aoi[stimulus_aoi] = {\"fixation_duration_sum\": 0, \"fixation_duration_mean\": 0, \"fixation_duration_std\": 0}\n",
    "                dict_features_per_aoi[stimulus_aoi] = {\"fixation_counts\": 0, \"fixation_duration_sum\": 0, \"fixation_duration_mean\": 0, \"fixation_duration_std\": 0, \"scan_distance_h\": 0, \"scan_distance_v\": 0, \"scan_distance_euclid\": 0, \"scan_hv_ratio\": 0, \"avg_sacc_length\": 0, \"scan_speed_h\": 0, \"scan_speed_v\": 0, \"scan_speed\": 0}\n",
    "            \n",
    "            df_gaze_data = user_data[document_id][\"dataframe\"]\n",
    "            relevance_label = []\n",
    "            system_relevance = []\n",
    "            for paragraph_num in range(0, user_data[document_id][\"num_paragraphs\"]):\n",
    "                relevance_label.append(int(user_data[document_id][\"perceived_relevance\"][paragraph_num]))\n",
    "                system_relevance.append(int(user_data[document_id][\"system_relevance\"][paragraph_num]))\n",
    "            \n",
    "            t = df_gaze_data[\"timestamp\"].values\n",
    "            x = df_gaze_data[\"gaze_x\"].values\n",
    "            y = df_gaze_data[\"gaze_y\"].values\n",
    "            y_abs = df_gaze_data[\"gaze_y_abs\"].values\n",
    "            \n",
    "            events = fixation_detection(t=t, x=x, y=y)\n",
    "            list_fixations = []\n",
    "            list_aoi_points = []\n",
    "            for (start, end) in events:\n",
    "                x_position = mean(x[start:end])\n",
    "                y_position = mean(y_abs[start:end])\n",
    "                fixation_duration = t[end] - t[start]\n",
    "                aoi = assign_aoi(scanpath_graph_representation_type=scanpath_graph_representation, current_stimulus_id=stimulus, x_point=x_position, y_point=y_position)\n",
    "                list_aoi_points.append(aoi)\n",
    "                list_fixations.append({\"start_time\": t[start], \"end_time\": t[end], \"gaze_x\": x_position,\n",
    "                                  \"gaze_y\": y_position, \"duration\": fixation_duration, \"aoi\": aoi})\n",
    "                dict_aoi_fixation_durations[aoi].append(fixation_duration)\n",
    "            aoi_scanpath = compute_path(scanpath_graph_representation_type=scanpath_graph_representation, aoi_list=list_aoi_points)\n",
    "    \n",
    "            # Compute Fixation Features\n",
    "            dict_fixation_counts_per_aoi = dict(Counter(list_aoi_points))  # Count the number of fixations in each AOI\n",
    "            for stimulus_aoi in list_stimulus_aois:\n",
    "                if stimulus_aoi not in dict_fixation_counts_per_aoi:\n",
    "                    dict_fixation_counts_per_aoi[stimulus_aoi] = 0\n",
    "                if dict_aoi_fixation_durations[stimulus_aoi]:\n",
    "                    dict_fixation_features_per_aoi[stimulus_aoi][\"fixation_duration_sum\"] = sum(dict_aoi_fixation_durations[stimulus_aoi])\n",
    "                    dict_fixation_features_per_aoi[stimulus_aoi][\"fixation_duration_mean\"] = mean(dict_aoi_fixation_durations[stimulus_aoi])\n",
    "                    if len(dict_aoi_fixation_durations[stimulus_aoi]) != 1:\n",
    "                        dict_fixation_features_per_aoi[stimulus_aoi][\"fixation_duration_std\"] = stdev(dict_aoi_fixation_durations[stimulus_aoi])\n",
    "                    else:\n",
    "                        dict_fixation_features_per_aoi[stimulus_aoi][\"fixation_duration_std\"] = 0\n",
    "                else:\n",
    "                    dict_fixation_features_per_aoi[stimulus_aoi][\"fixation_duration_sum\"] = 0\n",
    "                    dict_fixation_features_per_aoi[stimulus_aoi][\"fixation_duration_mean\"] = 0\n",
    "                    dict_fixation_features_per_aoi[stimulus_aoi][\"fixation_duration_std\"] = 0\n",
    "            \n",
    "            # Compute Saccade Features\n",
    "            dict_saccade_features_per_aoi = compute_saccade_aoi_features(list_fixations=list_fixations, list_stimulus_aois=list_stimulus_aois)\n",
    "            \n",
    "            # Combine Features\n",
    "            for stimulus_aoi in list_stimulus_aois:\n",
    "                dict_features_per_aoi[stimulus_aoi][\"fixation_counts\"] = dict_fixation_counts_per_aoi[stimulus_aoi]\n",
    "                dict_features_per_aoi[stimulus_aoi][\"fixation_duration_sum\"] = dict_fixation_features_per_aoi[stimulus_aoi][\"fixation_duration_sum\"]\n",
    "                dict_features_per_aoi[stimulus_aoi][\"fixation_duration_mean\"] = dict_fixation_features_per_aoi[stimulus_aoi][\"fixation_duration_mean\"]\n",
    "                dict_features_per_aoi[stimulus_aoi][\"fixation_duration_std\"] = dict_fixation_features_per_aoi[stimulus_aoi][\"fixation_duration_std\"]\n",
    "                dict_features_per_aoi[stimulus_aoi][\"scan_distance_h\"] = dict_saccade_features_per_aoi[stimulus_aoi][\"scan_distance_h\"]\n",
    "                dict_features_per_aoi[stimulus_aoi][\"scan_distance_v\"] = dict_saccade_features_per_aoi[stimulus_aoi][\"scan_distance_v\"]\n",
    "                dict_features_per_aoi[stimulus_aoi][\"scan_distance_euclid\"] = dict_saccade_features_per_aoi[stimulus_aoi][\"scan_distance_euclid\"]\n",
    "                dict_features_per_aoi[stimulus_aoi][\"scan_hv_ratio\"] = dict_saccade_features_per_aoi[stimulus_aoi][\"scan_hv_ratio\"]\n",
    "                dict_features_per_aoi[stimulus_aoi][\"avg_sacc_length\"] = dict_saccade_features_per_aoi[stimulus_aoi][\"avg_sacc_length\"]\n",
    "                dict_features_per_aoi[stimulus_aoi][\"scan_speed_h\"] = dict_saccade_features_per_aoi[stimulus_aoi][\"scan_speed_h\"]\n",
    "                dict_features_per_aoi[stimulus_aoi][\"scan_speed_v\"] = dict_saccade_features_per_aoi[stimulus_aoi][\"scan_speed_v\"]\n",
    "                dict_features_per_aoi[stimulus_aoi][\"scan_speed\"] = dict_saccade_features_per_aoi[stimulus_aoi][\"scan_speed\"]   \n",
    "            dict_features_per_aoi.pop(100, None)  # Delete empty spaces features\n",
    "            \n",
    "            # Compute Area Features\n",
    "            dict_area_features_per_aoi = None\n",
    "            if scanpath_graph_representation != \"Line\":\n",
    "                dict_area_features_per_aoi = compute_area_aoi_features(list_fixations, list_stimulus_aois, dict_features_per_aoi, stimulus_area=1)\n",
    "            \n",
    "            # Create Node Features List\n",
    "            dict_node_features = {}\n",
    "            if 100 in list_stimulus_aois:\n",
    "                list_stimulus_aois.remove(100)\n",
    "            if only_two_node_features:\n",
    "                for stimulus_aoi in list_stimulus_aois:\n",
    "                    dict_node_features[stimulus_aoi] = [dict_features_per_aoi[stimulus_aoi][\"fixation_counts\"], dict_features_per_aoi[stimulus_aoi][\"fixation_duration_sum\"]]\n",
    "                num_node_features = 2\n",
    "            else:\n",
    "                for stimulus_aoi in list_stimulus_aois:\n",
    "                    dict_node_features[stimulus_aoi] = [dict_features_per_aoi[stimulus_aoi][\"fixation_counts\"], dict_features_per_aoi[stimulus_aoi][\"fixation_duration_sum\"], dict_features_per_aoi[stimulus_aoi][\"fixation_duration_mean\"], dict_features_per_aoi[stimulus_aoi][\"fixation_duration_std\"], dict_features_per_aoi[stimulus_aoi][\"scan_distance_h\"], dict_features_per_aoi[stimulus_aoi][\"scan_distance_v\"], dict_features_per_aoi[stimulus_aoi][\"scan_distance_euclid\"], dict_features_per_aoi[stimulus_aoi][\"scan_hv_ratio\"], dict_features_per_aoi[stimulus_aoi][\"avg_sacc_length\"], dict_features_per_aoi[stimulus_aoi][\"scan_speed_h\"], dict_features_per_aoi[stimulus_aoi][\"scan_speed_v\"], dict_features_per_aoi[stimulus_aoi][\"scan_speed\"], dict_area_features_per_aoi[stimulus_aoi][\"box_area\"], dict_area_features_per_aoi[stimulus_aoi][\"box_area_per_time\"], dict_area_features_per_aoi[stimulus_aoi][\"fixns_per_box_area\"], dict_area_features_per_aoi[stimulus_aoi][\"hull_area_per_time\"], dict_area_features_per_aoi[stimulus_aoi][\"fixns_per_hull_area\"]]\n",
    "                num_node_features = 17\n",
    "            scanpath_aoi_dataclass = NodeAOIDataClass(stimulus=document_id, \n",
    "                                                      aoi_scanpath=aoi_scanpath, \n",
    "                                                      user_id=user,\n",
    "                                                      node_features=dict_node_features,\n",
    "                                                      label=relevance_label,\n",
    "                                                      system_label=system_relevance)\n",
    "            user_graph_data = asdict(extract_graph_data(dataclass_aoi_data=scanpath_aoi_dataclass))\n",
    "            output_df = pd.concat([output_df, pd.DataFrame([user_graph_data])], ignore_index=True)\n",
    "    output_df.to_csv(f\"../Data/Graph_Data/GoogleNQ_{scanpath_graph_representation}_{num_node_features}_Features.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "20225a2d049512e3",
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "6b0deb4518901ca5",
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

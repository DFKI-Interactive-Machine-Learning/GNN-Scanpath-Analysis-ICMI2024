{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import os\n",
    "from dataclasses import dataclass, asdict\n",
    "import pandas as pd\n",
    "import json\n",
    "from collections import Counter\n",
    "from data_loading.data_loader import SciBot_DataLoader  # Provided From https://github.com/DFKI-Interactive-Machine-Learning/gazeRE-dataset \n",
    "from gaze_event_detection.idt import fixation_detection\n",
    "from gaze_event_detection.saccade_detection import compute_saccade_aoi_features\n",
    "from gaze_event_detection.convex_hull_area_features import compute_area_aoi_features\n",
    "\n",
    "from statistics import mean, stdev\n",
    "os.environ[\"OMP_NUM_THREADS\"] = '1'\n",
    "from sklearn.cluster import AffinityPropagation"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "@dataclass\n",
    "class GraphDataClass:\n",
    "    __slots__ = [\"user_id\", \"stimulus\", \"label\", \"edge_index\", \"node_features\", \"system_label\", \"gREL_label\"]\n",
    "    user_id: str\n",
    "    stimulus: str\n",
    "    edge_index: list\n",
    "    node_features: list\n",
    "    label: bool\n",
    "    system_label: bool\n",
    "    gREL_label: str"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "781b5909db803732",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "@dataclass\n",
    "class AOIDataClass:\n",
    "    __slots__ = [\"user_id\", \"stimulus\", \"aoi_scanpath\", \"node_features\", \"label\", \"system_label\", \"gREL_label\"]\n",
    "    user_id: str\n",
    "    stimulus: str\n",
    "    label: bool\n",
    "    aoi_scanpath: list\n",
    "    node_features: dict\n",
    "    system_label: bool\n",
    "    gREL_label: str"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5e0ed3a325957c15",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def assign_aoi(scanpath_graph_representation_type: str, current_stimulus_id: str, x_point, y_point) -> int:\n",
    "    \"\"\"\n",
    "    For each fixation we assign which AOI it falls in.\n",
    "        The title takes number 0.\n",
    "        The paragraphs take numbers from 1 until #Paragraphs.\n",
    "        If the fixation is on an empty space or on the rating button it takes number 100.\n",
    "    We discard the rating button since the original publication didn't take it into perspective.\n",
    "    Based on the stimuli, we check that the fixation is with 700 and 1800 to make sure it fell on text and not on empty space. \n",
    "    This function does not deal with Cluster-based scanpath graph representations.\n",
    "    \"\"\"\n",
    "    aoi_id = 100\n",
    "    directory_path = f\"../Data/Stimuli_Coordinates_Data/gREL_{scanpath_graph_representation_type}_AOI.json\"\n",
    "    with open(directory_path, 'r') as fp:\n",
    "        dict_coordinates = json.load(fp)\n",
    "    if scanpath_graph_representation_type != \"Quartile\":\n",
    "        if dict_coordinates is not None:\n",
    "            if 700 <= x_point <= 1800:\n",
    "                for AOI in dict_coordinates[current_stimulus_id]:\n",
    "                    if dict_coordinates[current_stimulus_id][AOI][\"y_bottom\"] <= y_point <= dict_coordinates[current_stimulus_id][AOI][\"y_top\"]:\n",
    "                        aoi_id = AOI\n",
    "        else:\n",
    "            print(\"Wrong Coordinates\")\n",
    "    else:\n",
    "        \"\"\"\n",
    "        The Quartile-based scanpath graph representations were split based on x coordinates as well. \n",
    "        \"\"\"\n",
    "        if 700 <= x_point < 1250: \n",
    "            if dict_coordinates[current_stimulus_id][\"0\"][\"y_bottom\"] <= y_point < dict_coordinates[current_stimulus_id][\"0\"][\"y_top\"]:\n",
    "                aoi_id = 0\n",
    "            elif dict_coordinates[current_stimulus_id][\"1\"][\"y_bottom\"] <= y_point < dict_coordinates[current_stimulus_id][\"1\"][\"y_top\"]:\n",
    "                aoi_id = 2\n",
    "        elif 1250 <= x_point < 1800:\n",
    "            if dict_coordinates[current_stimulus_id][\"0\"][\"y_bottom\"] <= y_point < dict_coordinates[current_stimulus_id][\"0\"][\"y_top\"]:\n",
    "                aoi_id = 1\n",
    "            elif dict_coordinates[current_stimulus_id][\"1\"][\"y_bottom\"] <= y_point < dict_coordinates[current_stimulus_id][\"1\"][\"y_top\"]:\n",
    "                aoi_id = 3\n",
    "    return int(aoi_id)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "29645a6112380a12",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def get_stimulus_node_size(scanpath_graph_representation_type: str, current_stimulus_id: str) -> int:\n",
    "    \"\"\"\n",
    "    :param scanpath_graph_representation_type: Scanpath graph representation whether Paragraph, Line, or Quartile.\n",
    "    :param current_stimulus_id: Get the current stimulus ID to check the number of AOIs.\n",
    "    :return: Number of AOIs in the stimulus CSV + 1 because of the current setup where the image coordinates are not in the CSV file\n",
    "    \"\"\"\n",
    "    if scanpath_graph_representation_type != \"Quartile\":\n",
    "        directory_path = f\"../Data/Stimuli_Coordinates_Data/gREL_{scanpath_graph_representation_type}_AOI.json\"\n",
    "        with open(directory_path, 'r') as fp:\n",
    "            dict_coordinates = json.load(fp)\n",
    "        aoi_length = len(dict_coordinates[current_stimulus_id])\n",
    "    else:\n",
    "        aoi_length = 4\n",
    "    return aoi_length"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "35c6a0245fdf2419",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def get_maximum_node_size(scanpath_graph_representation_type: str):\n",
    "    maximum_aoi_length = 0\n",
    "    directory_path = f\"../Data/Stimuli_Coordinates_Data/gREL_{scanpath_graph_representation_type}_AOI.json\"\n",
    "    with open(directory_path, 'r') as fp:\n",
    "        dict_coordinates = json.load(fp)\n",
    "    for stimuli_id in dict_coordinates:\n",
    "        stimuli_length = len(dict_coordinates[stimuli_id])\n",
    "        if stimuli_length > maximum_aoi_length:\n",
    "            maximum_aoi_length = stimuli_length\n",
    "    return maximum_aoi_length"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7f285a1353524747",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def compute_path(scanpath_graph_representation_type: str, aoi_list: list) -> list:\n",
    "    \"\"\"\n",
    "    Here we extract the transitions between paragraphs.\n",
    "    \"\"\"\n",
    "    aoi_path = []\n",
    "    for i in range(len(aoi_list)):\n",
    "            if i == len(aoi_list) - 1:\n",
    "                aoi_path.append(aoi_list[i])\n",
    "            elif aoi_list[i] != aoi_list[i + 1]:  # If two consecutive fixations have different AOIs then it's a transition\n",
    "                aoi_path.append(aoi_list[i])\n",
    "    if scanpath_graph_representation_type != \"Cluster\":\n",
    "        aoi_path = [i for i in aoi_path if i != 100]  # We don't take the empty space transitions into account\n",
    "    return aoi_path"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b3a35fbe568e896f",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def extract_graph_data(dataclass_aoi_data: AOIDataClass) -> GraphDataClass:\n",
    "    \"\"\"\n",
    "    The GNN expects (maximum node ID = number of nodes-1) to be the maximum number that appears in the aoi_pairs.\n",
    "        We pre-add zeros in the aoi_features equal to the maximum number of AOIs we have in the stimuli.\n",
    "        Some AOI IDs have 0 fixations, which is why we pre-initiate the nodes with Zeros to make sure that all nodes, even empty ones, are accounted for. \n",
    "    node_size:param can either be the stimulus size using get_stimulus_node_size(), or the maximum node size for zero padding using get_maximum_node_size()\n",
    "    \"\"\"\n",
    "    scanpath = dataclass_aoi_data.aoi_scanpath\n",
    "    aoi_pairs = []\n",
    "    for i in range(0, len(scanpath)):\n",
    "            if 0 <= i < len(scanpath) - 1:\n",
    "                aoi_pairs.append([scanpath[i], scanpath[i + 1]])\n",
    "    graph_features = [value for key, value in dataclass_aoi_data.node_features.items()]\n",
    "    graph_data = GraphDataClass(user_id=dataclass_aoi_data.user_id, stimulus=dataclass_aoi_data.stimulus, label=dataclass_aoi_data.label, \n",
    "                                edge_index=aoi_pairs, node_features=graph_features, system_label=dataclass_aoi_data.system_label, gREL_label=dataclass_aoi_data.gREL_label)\n",
    "    return graph_data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "70c4085e49b7fc59",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\"\"\"\n",
    "The eye tracking data and the data loader are both from https://github.com/DFKI-Interactive-Machine-Learning/gazeRE-dataset \n",
    "The data folder was renamed Eye_Tracking_Data to avoid confusion since we have other data as well. \n",
    "\"\"\"\n",
    "# load data\n",
    "users_ids = [\"A01\", \"A03\", \"A04\", \"A06\", \"A07\", \"A08\", \"A09\", \"A10\", \"A11\", \"A12\", \"A13\",\n",
    "             \"B01\", \"B02\", \"B03\", \"B04\", \"B05\", \"B06\", \"B07\", \"B08\", \"B09\", \"B10\", \"B11\", \"B12\", \"B13\"]\n",
    "dataloader = SciBot_DataLoader(data_dir=\"../Data/Eye_Tracking_Data\", include_users=users_ids,\n",
    "                               gaze_data=True, reading_task=True, rating_task=False, training_data=False, gREL=True)\n",
    "items = dataloader.grel_reading.items()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b01fdd4863a5f60c",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\"\"\"\n",
    "Define graph data parameters\n",
    "    scanpath_graph_representation: \"Paragraph\", \"Line\", or \"Quartile\"\n",
    "    with_zero_padding: True, False\n",
    "    only_two_node_features: True, False\n",
    "\"\"\"\n",
    "for scanpath_graph_representation in [\"Paragraph\", \"Line\", \"Quartile\"]:\n",
    "    for with_zero_padding in [True, False]:\n",
    "        for only_two_node_features in [True, False]:\n",
    "            output_df = pd.DataFrame(columns=[\"user_id\", \"stimulus\", \"label\", \"edge_index\", \"node_features\", \"system_label\", \"gREL_label\"])\n",
    "            num_node_features = 0\n",
    "            for user, user_data in items:\n",
    "                for filename in os.listdir(f\"../Data/Eye_Tracking_Data/stimuli/g-REL/\"):\n",
    "                    document_id = filename[0:-6]\n",
    "                    stimulus = filename[0:-4]\n",
    "                    stimulus_number_of_aoi = get_stimulus_node_size(scanpath_graph_representation_type=scanpath_graph_representation, current_stimulus_id=stimulus)\n",
    "                    dict_aoi_fixation_durations = {100: []} \n",
    "                    dict_features_per_aoi = {100: {\"fixation_counts\": 0, \"fixation_duration_sum\": 0, \"fixation_duration_mean\": 0, \"fixation_duration_std\": 0, \"scan_distance_h\": 0, \"scan_distance_v\": 0, \"scan_distance_euclid\": 0, \"scan_hv_ratio\": 0, \"avg_sacc_length\": 0, \"scan_speed_h\": 0, \"scan_speed_v\": 0, \"scan_speed\": 0}} \n",
    "                    dict_fixation_features_per_aoi = {100: {\"fixation_duration_sum\": 0, \"fixation_duration_mean\": 0, \"fixation_duration_std\": 0}}  # 100 is the AOI ID for empty spaces, which will be removed\n",
    "                    list_stimulus_aois = [i for i in range(stimulus_number_of_aoi)]\n",
    "                    list_stimulus_aois.append(100)\n",
    "                    for stimulus_aoi in range(stimulus_number_of_aoi):\n",
    "                        dict_aoi_fixation_durations[stimulus_aoi] = []\n",
    "                        dict_fixation_features_per_aoi[stimulus_aoi] = {\"fixation_duration_sum\": 0, \"fixation_duration_mean\": 0, \"fixation_duration_std\": 0}\n",
    "                        dict_features_per_aoi[stimulus_aoi] = {\"fixation_counts\": 0, \"fixation_duration_sum\": 0, \"fixation_duration_mean\": 0, \"fixation_duration_std\": 0, \"scan_distance_h\": 0, \"scan_distance_v\": 0, \"scan_distance_euclid\": 0, \"scan_hv_ratio\": 0, \"avg_sacc_length\": 0, \"scan_speed_h\": 0, \"scan_speed_v\": 0, \"scan_speed\": 0}\n",
    "                    df_gaze_data = user_data[document_id][\"dataframe\"]\n",
    "                    relevance_label = user_data[document_id][\"perceived_relevance\"][0]\n",
    "                    system_relevance = user_data[document_id][\"system_relevance\"][0]\n",
    "                    gREL_relevance = user_data[document_id][\"g-rel_relevance\"][0]\n",
    "                    t = df_gaze_data[\"timestamp\"].values\n",
    "                    x = df_gaze_data[\"gaze_x\"].values\n",
    "                    y = df_gaze_data[\"gaze_y\"].values\n",
    "                    y_abs = df_gaze_data[\"gaze_y_abs\"].values\n",
    "                    events = fixation_detection(t=t, x=x, y=y)\n",
    "                    list_fixations = []\n",
    "                    list_aoi_points = []\n",
    "                    for (start, end) in events:\n",
    "                        x_position = mean(x[start:end])\n",
    "                        y_position = mean(y_abs[start:end])\n",
    "                        fixation_duration = t[end] - t[start]\n",
    "                        aoi = assign_aoi(scanpath_graph_representation_type=scanpath_graph_representation, current_stimulus_id=stimulus, x_point=x_position, y_point=y_position)\n",
    "                        list_aoi_points.append(aoi)\n",
    "                        list_fixations.append({\"start_time\": t[start], \"end_time\": t[end], \"gaze_x\": x_position,\n",
    "                                          \"gaze_y\": y_position, \"duration\": fixation_duration, \"aoi\": aoi})\n",
    "                        dict_aoi_fixation_durations[aoi].append(fixation_duration)  \n",
    "                    aoi_scanpath = compute_path(scanpath_graph_representation_type=scanpath_graph_representation, aoi_list=list_aoi_points)\n",
    "                    # Compute Fixation Features\n",
    "                    dict_fixation_counts_per_aoi = dict(Counter(list_aoi_points))  # Count the number of fixations in each AOI\n",
    "                    for stimulus_aoi in list_stimulus_aois:\n",
    "                        if stimulus_aoi not in dict_fixation_counts_per_aoi:\n",
    "                            dict_fixation_counts_per_aoi[stimulus_aoi] = 0\n",
    "                        if dict_aoi_fixation_durations[stimulus_aoi]:\n",
    "                            dict_fixation_features_per_aoi[stimulus_aoi][\"fixation_duration_sum\"] = sum(dict_aoi_fixation_durations[stimulus_aoi])\n",
    "                            dict_fixation_features_per_aoi[stimulus_aoi][\"fixation_duration_mean\"] = mean(dict_aoi_fixation_durations[stimulus_aoi])\n",
    "                            if len(dict_aoi_fixation_durations[stimulus_aoi]) != 1:\n",
    "                                dict_fixation_features_per_aoi[stimulus_aoi][\"fixation_duration_std\"] = stdev(dict_aoi_fixation_durations[stimulus_aoi])\n",
    "                            else:\n",
    "                                dict_fixation_features_per_aoi[stimulus_aoi][\"fixation_duration_std\"] = 0\n",
    "                        else:\n",
    "                            dict_fixation_features_per_aoi[stimulus_aoi][\"fixation_duration_sum\"] = 0\n",
    "                            dict_fixation_features_per_aoi[stimulus_aoi][\"fixation_duration_mean\"] = 0\n",
    "                            dict_fixation_features_per_aoi[stimulus_aoi][\"fixation_duration_std\"] = 0\n",
    "                    # Compute Saccade Features\n",
    "                    dict_saccade_features_per_aoi = compute_saccade_aoi_features(list_fixations=list_fixations, list_stimulus_aois=list_stimulus_aois)\n",
    "                    # Combine Features\n",
    "                    for stimulus_aoi in list_stimulus_aois:\n",
    "                        dict_features_per_aoi[stimulus_aoi][\"fixation_counts\"] = dict_fixation_counts_per_aoi[stimulus_aoi]\n",
    "                        dict_features_per_aoi[stimulus_aoi][\"fixation_duration_sum\"] = dict_fixation_features_per_aoi[stimulus_aoi][\"fixation_duration_sum\"]\n",
    "                        dict_features_per_aoi[stimulus_aoi][\"fixation_duration_mean\"] = dict_fixation_features_per_aoi[stimulus_aoi][\"fixation_duration_mean\"]\n",
    "                        dict_features_per_aoi[stimulus_aoi][\"fixation_duration_std\"] = dict_fixation_features_per_aoi[stimulus_aoi][\"fixation_duration_std\"]\n",
    "                        dict_features_per_aoi[stimulus_aoi][\"scan_distance_h\"] = dict_saccade_features_per_aoi[stimulus_aoi][\"scan_distance_h\"]\n",
    "                        dict_features_per_aoi[stimulus_aoi][\"scan_distance_v\"] = dict_saccade_features_per_aoi[stimulus_aoi][\"scan_distance_v\"]\n",
    "                        dict_features_per_aoi[stimulus_aoi][\"scan_distance_euclid\"] = dict_saccade_features_per_aoi[stimulus_aoi][\"scan_distance_euclid\"]\n",
    "                        dict_features_per_aoi[stimulus_aoi][\"scan_hv_ratio\"] = dict_saccade_features_per_aoi[stimulus_aoi][\"scan_hv_ratio\"]\n",
    "                        dict_features_per_aoi[stimulus_aoi][\"avg_sacc_length\"] = dict_saccade_features_per_aoi[stimulus_aoi][\"avg_sacc_length\"]\n",
    "                        dict_features_per_aoi[stimulus_aoi][\"scan_speed_h\"] = dict_saccade_features_per_aoi[stimulus_aoi][\"scan_speed_h\"]\n",
    "                        dict_features_per_aoi[stimulus_aoi][\"scan_speed_v\"] = dict_saccade_features_per_aoi[stimulus_aoi][\"scan_speed_v\"]\n",
    "                        dict_features_per_aoi[stimulus_aoi][\"scan_speed\"] = dict_saccade_features_per_aoi[stimulus_aoi][\"scan_speed\"]   \n",
    "                    dict_features_per_aoi.pop(100, None)  # Delete empty spaces features\n",
    "                    \n",
    "                    # Compute Area Features\n",
    "                    dict_area_features_per_aoi = None\n",
    "                    if scanpath_graph_representation != \"Line\":\n",
    "                        dict_area_features_per_aoi = compute_area_aoi_features(list_fixations, list_stimulus_aois, dict_features_per_aoi, stimulus_area=1)\n",
    "                    \n",
    "                    # Create Node Features List\n",
    "                    dict_node_features = {}\n",
    "                    if 100 in list_stimulus_aois:\n",
    "                        list_stimulus_aois.remove(100)\n",
    "                    if only_two_node_features:\n",
    "                        for stimulus_aoi in list_stimulus_aois:\n",
    "                            dict_node_features[stimulus_aoi] = [dict_features_per_aoi[stimulus_aoi][\"fixation_counts\"], dict_features_per_aoi[stimulus_aoi][\"fixation_duration_sum\"]]\n",
    "                        num_node_features = 2\n",
    "                    else:\n",
    "                        if scanpath_graph_representation != \"Line\":\n",
    "                            for stimulus_aoi in list_stimulus_aois:\n",
    "                                dict_node_features[stimulus_aoi] = [dict_features_per_aoi[stimulus_aoi][\"fixation_counts\"], dict_features_per_aoi[stimulus_aoi][\"fixation_duration_sum\"], dict_features_per_aoi[stimulus_aoi][\"fixation_duration_mean\"], dict_features_per_aoi[stimulus_aoi][\"fixation_duration_std\"], dict_features_per_aoi[stimulus_aoi][\"scan_distance_h\"], dict_features_per_aoi[stimulus_aoi][\"scan_distance_v\"], dict_features_per_aoi[stimulus_aoi][\"scan_distance_euclid\"], dict_features_per_aoi[stimulus_aoi][\"scan_hv_ratio\"], dict_features_per_aoi[stimulus_aoi][\"avg_sacc_length\"], dict_features_per_aoi[stimulus_aoi][\"scan_speed_h\"], dict_features_per_aoi[stimulus_aoi][\"scan_speed_v\"], dict_features_per_aoi[stimulus_aoi][\"scan_speed\"], dict_area_features_per_aoi[stimulus_aoi][\"box_area\"], dict_area_features_per_aoi[stimulus_aoi][\"box_area_per_time\"], dict_area_features_per_aoi[stimulus_aoi][\"fixns_per_box_area\"], dict_area_features_per_aoi[stimulus_aoi][\"hull_area_per_time\"], dict_area_features_per_aoi[stimulus_aoi][\"fixns_per_hull_area\"]]\n",
    "                        else:\n",
    "                            for stimulus_aoi in list_stimulus_aois:\n",
    "                                dict_node_features[stimulus_aoi] = [dict_features_per_aoi[stimulus_aoi][\"fixation_counts\"], dict_features_per_aoi[stimulus_aoi][\"fixation_duration_sum\"], dict_features_per_aoi[stimulus_aoi][\"fixation_duration_mean\"], dict_features_per_aoi[stimulus_aoi][\"fixation_duration_std\"], dict_features_per_aoi[stimulus_aoi][\"scan_distance_h\"], dict_features_per_aoi[stimulus_aoi][\"scan_distance_v\"], dict_features_per_aoi[stimulus_aoi][\"scan_distance_euclid\"], dict_features_per_aoi[stimulus_aoi][\"scan_hv_ratio\"], dict_features_per_aoi[stimulus_aoi][\"avg_sacc_length\"], dict_features_per_aoi[stimulus_aoi][\"scan_speed_h\"], dict_features_per_aoi[stimulus_aoi][\"scan_speed_v\"], dict_features_per_aoi[stimulus_aoi][\"scan_speed\"]]\n",
    "                        num_node_features = 17\n",
    "                    scanpath_aoi_dataclass = AOIDataClass(stimulus=document_id, aoi_scanpath=aoi_scanpath, user_id=user,\n",
    "                                                          node_features=dict_node_features,\n",
    "                                                          label=relevance_label,\n",
    "                                                          system_label=system_relevance,\n",
    "                                                          gREL_label=gREL_relevance)\n",
    "                    user_graph_data = asdict(extract_graph_data(dataclass_aoi_data=scanpath_aoi_dataclass))\n",
    "                    output_df = pd.concat([output_df, pd.DataFrame([user_graph_data])], ignore_index=True)\n",
    "            output_df.to_csv(f\"../Data/Graph_Data/gREL_{scanpath_graph_representation}_{num_node_features}_Features.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8c7100e0879938a8",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\"\"\"\n",
    "Define graph data parameters\n",
    "    scanpath_graph_representation: \"Cluster\"\n",
    "    only_two_node_features: True, False\n",
    "\"\"\"\n",
    "scanpath_graph_representation = \"Cluster\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f374ef3d9576335e",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for only_two_node_features in [True, False]:\n",
    "    output_df = pd.DataFrame(columns=[\"user_id\", \"stimulus\", \"label\", \"edge_index\", \"node_features\", \"system_label\", \"gREL_label\"])\n",
    "    num_node_features = 0\n",
    "    for user, user_data in items:\n",
    "        for filename in os.listdir(f\"../Data/Eye_Tracking_Data/stimuli/g-REL/\"):\n",
    "            document_id = filename[0:-6]\n",
    "            stimulus = filename[0:-4]\n",
    "            df_gaze_data = user_data[document_id][\"dataframe\"]\n",
    "            relevance_label = user_data[document_id][\"perceived_relevance\"][0]\n",
    "            system_relevance = user_data[document_id][\"system_relevance\"][0]\n",
    "            gREL_relevance = user_data[document_id][\"g-rel_relevance\"][0]\n",
    "            t = df_gaze_data[\"timestamp\"].values\n",
    "            x = df_gaze_data[\"gaze_x\"].values\n",
    "            y = df_gaze_data[\"gaze_y\"].values\n",
    "            y_abs = df_gaze_data[\"gaze_y_abs\"].values\n",
    "            events = fixation_detection(t=t, x=x, y=y)\n",
    "            fixations = {\"x\": [], \"y\": []}\n",
    "            fixations_extra_info = {\"start_time\": [], \"end_time\": []}\n",
    "            fixation_duration_list = []\n",
    "            for (start, end) in events:\n",
    "                x_position = mean(x[start:end])\n",
    "                y_position = mean(y_abs[start:end])\n",
    "                if 700 <= x_position <= 1800:  # To remove the rating button and empty space\n",
    "                    fixation_duration = t[end] - t[start]\n",
    "                    fixations[\"x\"].append(x_position)\n",
    "                    fixations[\"y\"].append(y_position)\n",
    "                    fixations_extra_info[\"start_time\"].append(t[start])\n",
    "                    fixations_extra_info[\"end_time\"].append(t[end])\n",
    "                    fixation_duration_list.append(fixation_duration)\n",
    "            fixations_df = pd.DataFrame(fixations)\n",
    "            clustering = AffinityPropagation(random_state=0)\n",
    "            list_aoi_points = clustering.fit_predict(fixations_df)\n",
    "            fixations_df[\"cluster\"] = list_aoi_points\n",
    "            # Rename the clusters to be consistent from up to down\n",
    "            # Get each cluster's center coordinate ordered by their label 0, 1, ...\n",
    "            cluster_centers = clustering.cluster_centers_\n",
    "            cluster_centers_df = pd.DataFrame(cluster_centers, columns=[\"x\", \"y\"])\n",
    "            cluster_centers_df = cluster_centers_df.sort_values(by=[\"x\"])  # Sort the clusters\n",
    "            cluster_centers_df = cluster_centers_df.sort_values(by=[\"y\"], kind=\"mergesort\", ascending=False)\n",
    "            cluster_centers_df[\"old_index\"] = cluster_centers_df.index  # Save the old labels\n",
    "            cluster_centers_df = cluster_centers_df.reset_index()\n",
    "            cluster_centers_df[\"new_index\"] = cluster_centers_df.index  # Save the new labels\n",
    "            # Change the node labels\n",
    "            fixations_df[\"cluster\"] = fixations_df[\"cluster\"].replace(cluster_centers_df[\"old_index\"].values.tolist(),\n",
    "                                                                      cluster_centers_df[\"new_index\"].values.tolist())\n",
    "            fixations_df[\"duration\"] = fixation_duration_list\n",
    "            fixations_df[\"start_time\"] = fixations_extra_info[\"start_time\"]\n",
    "            fixations_df[\"end_time\"] = fixations_extra_info[\"end_time\"]\n",
    "            \n",
    "            aoi_scanpath = compute_path(scanpath_graph_representation_type=scanpath_graph_representation, aoi_list=fixations_df[\"cluster\"].tolist())\n",
    "            aoi_duration_df_fixation_features_sum = fixations_df.groupby([\"cluster\"]).duration.sum().reset_index().rename(columns={\"duration\": \"sum\"}) \n",
    "            aoi_duration_df_fixation_features_mean = fixations_df.groupby([\"cluster\"]).duration.mean().reset_index().rename(columns={\"duration\": \"mean\"}) \n",
    "            aoi_duration_df_fixation_features_std = fixations_df.groupby([\"cluster\"]).duration.std().reset_index().rename(columns={\"duration\": \"std\"}).fillna(0)\n",
    "            aoi_duration_df_fixation_features = pd.merge(aoi_duration_df_fixation_features_sum, aoi_duration_df_fixation_features_mean, on=\"cluster\")\n",
    "            aoi_duration_df_fixation_features = pd.merge(aoi_duration_df_fixation_features, aoi_duration_df_fixation_features_std, on=\"cluster\")\n",
    "            dict_fixation_features_per_aoi = {k: {\"fixation_duration_sum\": s, \"fixation_duration_mean\":m, \"fixation_duration_std\":std} for k, s, m, std in zip(aoi_duration_df_fixation_features.cluster, aoi_duration_df_fixation_features[\"sum\"], aoi_duration_df_fixation_features[\"mean\"], aoi_duration_df_fixation_features[\"std\"])}\n",
    "            \n",
    "            # Edit the format to fit the feature extraction functions\n",
    "            fixations_df.rename(columns={\"x\": \"gaze_x\", \"y\": \"gaze_y\", \"cluster\": \"aoi\"}, inplace=True)    \n",
    "            list_fixations = fixations_df.to_dict(\"records\")\n",
    "            list_stimulus_aois = list(set(list_aoi_points))\n",
    "            # dict_fixation_counts_per_aoi = dict(Counter(list_aoi_points))  # Count the number of fixations in each AOI\n",
    "            dict_fixation_counts_per_aoi = fixations_df[\"aoi\"].value_counts().to_dict()\n",
    "            dict_features_per_aoi = {}\n",
    "            for stimulus_aoi in list_stimulus_aois:\n",
    "                dict_features_per_aoi[stimulus_aoi] = {\"fixation_counts\": 0, \"fixation_duration_sum\": 0, \"fixation_duration_mean\": 0, \"fixation_duration_std\": 0, \"scan_distance_h\": 0, \"scan_distance_v\": 0, \"scan_distance_euclid\": 0, \"scan_hv_ratio\": 0, \"avg_sacc_length\": 0, \"scan_speed_h\": 0, \"scan_speed_v\": 0, \"scan_speed\": 0}\n",
    "            \n",
    "            # Compute Saccade Features\n",
    "            dict_saccade_features_per_aoi = compute_saccade_aoi_features(list_fixations=list_fixations, list_stimulus_aois=list_stimulus_aois)\n",
    "            # Combine Features\n",
    "            for stimulus_aoi in list_stimulus_aois:\n",
    "                dict_features_per_aoi[stimulus_aoi][\"fixation_counts\"] = dict_fixation_counts_per_aoi[stimulus_aoi]\n",
    "                dict_features_per_aoi[stimulus_aoi][\"fixation_duration_sum\"] = dict_fixation_features_per_aoi[stimulus_aoi][\"fixation_duration_sum\"]\n",
    "                dict_features_per_aoi[stimulus_aoi][\"fixation_duration_mean\"] = dict_fixation_features_per_aoi[stimulus_aoi][\"fixation_duration_mean\"]\n",
    "                dict_features_per_aoi[stimulus_aoi][\"fixation_duration_std\"] = dict_fixation_features_per_aoi[stimulus_aoi][\"fixation_duration_std\"]\n",
    "                dict_features_per_aoi[stimulus_aoi][\"scan_distance_h\"] = dict_saccade_features_per_aoi[stimulus_aoi][\"scan_distance_h\"]\n",
    "                dict_features_per_aoi[stimulus_aoi][\"scan_distance_v\"] = dict_saccade_features_per_aoi[stimulus_aoi][\"scan_distance_v\"]\n",
    "                dict_features_per_aoi[stimulus_aoi][\"scan_distance_euclid\"] = dict_saccade_features_per_aoi[stimulus_aoi][\"scan_distance_euclid\"]\n",
    "                dict_features_per_aoi[stimulus_aoi][\"scan_hv_ratio\"] = dict_saccade_features_per_aoi[stimulus_aoi][\"scan_hv_ratio\"]\n",
    "                dict_features_per_aoi[stimulus_aoi][\"avg_sacc_length\"] = dict_saccade_features_per_aoi[stimulus_aoi][\"avg_sacc_length\"]\n",
    "                dict_features_per_aoi[stimulus_aoi][\"scan_speed_h\"] = dict_saccade_features_per_aoi[stimulus_aoi][\"scan_speed_h\"]\n",
    "                dict_features_per_aoi[stimulus_aoi][\"scan_speed_v\"] = dict_saccade_features_per_aoi[stimulus_aoi][\"scan_speed_v\"]\n",
    "                dict_features_per_aoi[stimulus_aoi][\"scan_speed\"] = dict_saccade_features_per_aoi[stimulus_aoi][\"scan_speed\"]   \n",
    "            dict_features_per_aoi.pop(100, None)  # Delete empty spaces features\n",
    "            \n",
    "            # Compute Area Features\n",
    "            \n",
    "            dict_area_features_per_aoi = compute_area_aoi_features(list_fixations, list_stimulus_aois, dict_features_per_aoi, stimulus_area=1)\n",
    "            \n",
    "            # Create Node Features List\n",
    "            dict_node_features = {}\n",
    "    \n",
    "            if only_two_node_features:\n",
    "                for stimulus_aoi in list_stimulus_aois:\n",
    "                    dict_node_features[stimulus_aoi] = [dict_features_per_aoi[stimulus_aoi][\"fixation_counts\"], dict_features_per_aoi[stimulus_aoi][\"fixation_duration_sum\"]]\n",
    "                num_node_features = 2\n",
    "            else:\n",
    "                for stimulus_aoi in list_stimulus_aois:\n",
    "                    dict_node_features[stimulus_aoi] = [dict_features_per_aoi[stimulus_aoi][\"fixation_counts\"], dict_features_per_aoi[stimulus_aoi][\"fixation_duration_sum\"], dict_features_per_aoi[stimulus_aoi][\"fixation_duration_mean\"], dict_features_per_aoi[stimulus_aoi][\"fixation_duration_std\"], dict_features_per_aoi[stimulus_aoi][\"scan_distance_h\"], dict_features_per_aoi[stimulus_aoi][\"scan_distance_v\"], dict_features_per_aoi[stimulus_aoi][\"scan_distance_euclid\"], dict_features_per_aoi[stimulus_aoi][\"scan_hv_ratio\"], dict_features_per_aoi[stimulus_aoi][\"avg_sacc_length\"], dict_features_per_aoi[stimulus_aoi][\"scan_speed_h\"], dict_features_per_aoi[stimulus_aoi][\"scan_speed_v\"], dict_features_per_aoi[stimulus_aoi][\"scan_speed\"], dict_area_features_per_aoi[stimulus_aoi][\"box_area\"], dict_area_features_per_aoi[stimulus_aoi][\"box_area_per_time\"], dict_area_features_per_aoi[stimulus_aoi][\"fixns_per_box_area\"], dict_area_features_per_aoi[stimulus_aoi][\"hull_area_per_time\"], dict_area_features_per_aoi[stimulus_aoi][\"fixns_per_hull_area\"]]\n",
    "                num_node_features = 17\n",
    "            \n",
    "            scanpath_aoi_dataclass = AOIDataClass(stimulus=document_id, aoi_scanpath=aoi_scanpath, user_id=user,\n",
    "                                                  node_features=dict_node_features,\n",
    "                                                  label=relevance_label,\n",
    "                                                  system_label=system_relevance,\n",
    "                                                  gREL_label=gREL_relevance)\n",
    "            user_graph_data = asdict(extract_graph_data(dataclass_aoi_data=scanpath_aoi_dataclass))\n",
    "            output_df = pd.concat([output_df, pd.DataFrame([user_graph_data])], ignore_index=True)\n",
    "    output_df.to_csv(f\"../Data/Graph_Data/gREL_{scanpath_graph_representation}_Affinity_{num_node_features}_Features.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bddcd0d92981b811",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "dd8896c82b8bf011",
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

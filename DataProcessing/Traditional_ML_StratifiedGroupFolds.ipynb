{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "from sklearn.metrics import balanced_accuracy_score, f1_score, roc_auc_score, confusion_matrix, log_loss\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from imblearn.pipeline import make_pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from typing import Tuple \n",
    "from sklearn.model_selection import StratifiedGroupKFold"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def load_data(corpus: str):\n",
    "    \"\"\"\n",
    "    Corpus\n",
    "        - gREL\n",
    "        - GoogleNQ\n",
    "    \"\"\"\n",
    "    # The data splits are from the codes of https://github.com/DFKI-Interactive-Machine-Learning/gazeRE-dataset \n",
    "    scanpath_all = pd.read_csv(f\"../Data/Feature_Data/{corpus}.csv\")\n",
    "    if corpus == \"gREL\":\n",
    "        scanpath_agree = scanpath_all.loc[scanpath_all[\"label\"] == scanpath_all[\"system_label\"]]\n",
    "        scanpath_agree = scanpath_agree.loc[scanpath_agree[\"gREL_label\"] != \"t\"]\n",
    "        scanpath_topical = scanpath_all.loc[scanpath_all[\"gREL_label\"] == \"t\"]\n",
    "    else:\n",
    "        scanpath_agree = scanpath_all.loc[scanpath_all[\"label\"] == scanpath_all[\"system_label\"]]\n",
    "        scanpath_topical = None\n",
    "    return scanpath_all, scanpath_agree, scanpath_topical"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "10efe1b738f1cc72",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def prepare_data(df: pd.DataFrame, feature_list: list) -> Tuple[list, list, list]:\n",
    "    features = df[feature_list]\n",
    "    dataset_list = features.values.tolist()\n",
    "    labels = df[[\"label\"]].astype({\"label\": int}).values.tolist()\n",
    "    labels_list = [item for sublist in labels for item in sublist]\n",
    "    user_groups_list = df[[\"user_id\"]].values.tolist()\n",
    "    return dataset_list, labels_list, user_groups_list"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9aad8550308084d3",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def evaluate_results(true_labels: list, prediction_labels: list, prediction_proba: list):\n",
    "    accuracy = balanced_accuracy_score(true_labels, prediction_labels)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true=true_labels, y_pred=prediction_labels, labels=[0, 1]).ravel()\n",
    "    if (tp + fp) == 0 and (tp + fn) == 0:\n",
    "        print(\"F1 Zero\")\n",
    "        f1_result = 0\n",
    "    else:\n",
    "        f1_result = f1_score(true_labels, prediction_labels, labels=[0, 1])\n",
    "    if tp + fn == 0:\n",
    "        print(\"TPR Zero\")\n",
    "        tpr = 0\n",
    "    else:\n",
    "        tpr = tp / (tp + fn)\n",
    "    if tn + fp == 0:\n",
    "        print(\"FPR Zero\")\n",
    "        fpr = 0\n",
    "    else:\n",
    "        fpr = fp / (tn + fp)\n",
    "    loss_score = log_loss(y_true=true_labels, y_pred=prediction_labels, labels=[0, 1])\n",
    "    roc_auc = roc_auc_score(y_true=true_labels, y_score=prediction_proba, average=\"weighted\", labels=[0, 1])\n",
    "    return f1_result, accuracy, tpr, fpr, loss_score, roc_auc, tn, fp, fn, tp"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bf29d71e310133c1",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "list_all_features = ['f_fixn_n', 'f_fixn_dur_sum', 'f_fixn_dur_avg', 'f_fixn_dur_sd', \n",
    "                     'f_scan_distance_h', 'f_scan_distance_v', 'f_scan_distance_euclid', 'f_scan_hv_ratio', \n",
    "                     'f_avg_sacc_length', 'f_scan_speed_h', 'f_scan_speed_v', 'f_scan_speed', \n",
    "                     'f_box_area', 'f_box_area_per_time', 'f_fixns_per_box_area', 'f_hull_area_per_time', \n",
    "                     'f_fixns_per_hull_area']\n",
    "list_two_features = ['f_hull_area_per_time', 'f_fixns_per_hull_area']\n",
    "\n",
    "def process_df_stratified_group_folds(df: pd.DataFrame, corpus: str, data_type: str, which_model: str):\n",
    "    df_history_testing = pd.DataFrame(columns=[\"user_id\", \"f1_score_testing\", \"accuracy_testing\", \"tpr_testing\", \"fpr_testing\", \"loss_testing\", \"auc_testing\", \"tn_testing\", \"fp_testing\", \"fn_testing\", \"tp_testing\", \"feature_list\"])\n",
    "    for feature_list in [list_all_features, list_two_features]:\n",
    "        # Cross-validation loop for the testing data\n",
    "        fold_splits = StratifiedGroupKFold(n_splits=5, shuffle=True, random_state=256)\n",
    "        list_users_dataset_all, list_users_labels_all, list_users_groups_ids_all = prepare_data(df, feature_list)\n",
    "        \n",
    "        for i, (training_index, testing_index) in enumerate(\n",
    "                fold_splits.split(list_users_dataset_all, list_users_labels_all, list_users_groups_ids_all)):\n",
    "            # Dict to save the results of these users\n",
    "            dict_results = {}\n",
    "            # Prepare data for training\n",
    "            list_users_dataset_training = [list_users_dataset_all[train_ind] for train_ind in training_index]\n",
    "            list_users_labels_training = [list_users_labels_all[train_ind] for train_ind in training_index]\n",
    "            # Prepare data for testing\n",
    "            list_user_dataset_testing = [list_users_dataset_all[k] for k in testing_index]\n",
    "            list_user_labels_testing = [list_users_labels_all[k] for k in testing_index]\n",
    "            list_user_group_ids_testing = [list_users_groups_ids_all[k] for k in testing_index]\n",
    "            list_user_group_ids_testing = [item for sublist in list_user_group_ids_testing for item in sublist]\n",
    "            list_user_group_ids_testing_unduplicated = list(dict.fromkeys(list_user_group_ids_testing))\n",
    "            string_user_group_ids_testing_unduplicated = ', '.join(list_user_group_ids_testing_unduplicated)\n",
    "            \n",
    "            # Initialise the model\n",
    "            if which_model == \"RF\":\n",
    "                model = RandomForestClassifier(n_estimators=100, random_state=256)\n",
    "            elif which_model == \"SVM_SMOTE\":\n",
    "                model = make_pipeline(SMOTE(), StandardScaler(), SVC(kernel=\"rbf\", C=1, probability=True))\n",
    "            elif which_model == \"RF_SMOTE\":\n",
    "                model = make_pipeline(SMOTE(), StandardScaler(), RandomForestClassifier(n_estimators=100, random_state=256))\n",
    "            else:\n",
    "                model = SVC(probability=True)\n",
    "            \n",
    "            # Train the model\n",
    "            model.fit(list_users_dataset_training, list_users_labels_training)\n",
    "            # Test the model\n",
    "            list_predicted_labels_testing = model.predict(list_user_dataset_testing)\n",
    "            list_positive_predicted_proba_testing = model.predict_proba(list_user_dataset_testing)[:, 1]  # keep probabilities for the positive outcome only\n",
    "            testing_f1_score, testing_accuracy, testing_tpr, testing_fpr, testing_loss, testing_auc, testing_tn, testing_fp, testing_fn, testing_tp = (\n",
    "                evaluate_results(true_labels=list_user_labels_testing, prediction_labels=list_predicted_labels_testing, prediction_proba=list_positive_predicted_proba_testing))\n",
    "    \n",
    "            dict_results[\"f1_score_testing\"] = testing_f1_score\n",
    "            dict_results[\"accuracy_testing\"] = testing_accuracy\n",
    "            dict_results[\"tpr_testing\"] = testing_tpr\n",
    "            dict_results[\"fpr_testing\"] = testing_fpr\n",
    "            dict_results[\"loss_testing\"] = testing_loss\n",
    "            dict_results[\"auc_testing\"] = testing_auc\n",
    "            dict_results[\"tn_testing\"] = testing_tn\n",
    "            dict_results[\"fp_testing\"] = testing_fp\n",
    "            dict_results[\"fn_testing\"] = testing_fn\n",
    "            dict_results[\"tp_testing\"] = testing_tp\n",
    "            dict_results[\"user_id\"] = string_user_group_ids_testing_unduplicated\n",
    "            dict_results[\"feature_list\"] = len(feature_list)\n",
    "    \n",
    "            # Save the results for this user\n",
    "            df_history_testing = pd.concat([df_history_testing, pd.DataFrame([dict_results])],ignore_index=True)\n",
    "            df_history_testing.to_csv(f'../Results/Traditional_ML/{corpus}_{which_model}_{data_type}_{len(feature_list)}_Features.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7037f399eff8e0a2",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Stratified Groups"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "47c319bf72b96dab"
  },
  {
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "Corpus\n",
    "    - gREL\n",
    "    - GoogleNQ\n",
    "Which_Model\n",
    "    - RF\n",
    "    - SVM\n",
    "    - RF_SMOTE\n",
    "    - SVM_SMOTE\n",
    "\"\"\"\n",
    "for Corpus in [\"gREL\", \"GoogleNQ\"]:\n",
    "    for Which_Model in [\"RF_SMOTE\", \"RF\", \"SVM\", \"SVM_SMOTE\"]:\n",
    "            scanpath_df_all, scanpath_df_agree, scanpath_df_topical = load_data(corpus=Corpus)\n",
    "            print(\"Agree\")\n",
    "            process_df_stratified_group_folds(df=scanpath_df_agree, corpus=Corpus, data_type=\"Agree\", which_model=Which_Model)\n",
    "            if Corpus == \"gREL\":\n",
    "                print(\"Topical\")\n",
    "                process_df_stratified_group_folds(df=scanpath_df_topical, corpus=Corpus, data_type=\"Topical\", which_model=Which_Model)\n",
    "            print(\"All\")\n",
    "            process_df_stratified_group_folds(df=scanpath_df_all, corpus=Corpus, data_type=\"All\", which_model=Which_Model)\n",
    "            print(f\"{Corpus} {Which_Model} Finished\") \n",
    "    print(f\"{Corpus} Finished\") "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5cb9a5ea6fbf5d09",
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
